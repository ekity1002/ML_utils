{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport csv\nimport pandas as pd\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nDATA_DIR = '/kaggle/input/movielens-100k-dataset/ml-100k'\nOUTPUT_DIR = './'\n\nclass Config:\n    device='cpu'\n    epochs=40\n    seed=17\n    train_bs=8\n    valid_bs=8\n    embedding_dim=20\n    lr=1e-2\n    num_workers=None       \n    verbose_step=100\n    \ndef torch_seed_everything(seed_value=777):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nconfig=Config()\ntorch_seed_everything(config.seed)","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATA_DIR, 'u.data'), sep='\\t', header=None)\ndf.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n#df = df.sort_values('timestamp').reset_index(drop=True)\nn_user = df.user_id.nunique()\nn_item = df.item_id.nunique()\ndf","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"       user_id  item_id  rating  timestamp\n0          196      242       3  881250949\n1          186      302       3  891717742\n2           22      377       1  878887116\n3          244       51       2  880606923\n4          166      346       1  886397596\n...        ...      ...     ...        ...\n99995      880      476       3  880175444\n99996      716      204       5  879795543\n99997      276     1090       1  874795795\n99998       13      225       2  882399156\n99999       12      203       3  879959583\n\n[100000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n      <td>891717742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n      <td>878887116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n      <td>880606923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n      <td>886397596</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>880</td>\n      <td>476</td>\n      <td>3</td>\n      <td>880175444</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>716</td>\n      <td>204</td>\n      <td>5</td>\n      <td>879795543</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>276</td>\n      <td>1090</td>\n      <td>1</td>\n      <td>874795795</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>13</td>\n      <td>225</td>\n      <td>2</td>\n      <td>882399156</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>12</td>\n      <td>203</td>\n      <td>3</td>\n      <td>879959583</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('user_num', n_user)\nprint('item_num', n_item)","execution_count":24,"outputs":[{"output_type":"stream","text":"user_num 943\nitem_num 1682\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# split data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['user_id'], random_state=config.seed)\nassert train_df.user_id.nunique() == valid_df.user_id.nunique()\nprint(train_df.shape, valid_df.shape)\n#print(valid_df.user_id.nunique())","execution_count":25,"outputs":[{"output_type":"stream","text":"(80000, 4) (20000, 4)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MovieLensDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        user_id, item_id, rating, _ = self.df.iloc[idx]\n        # index starts with 0\n        sample = {\"user\": user_id - 1, \"item\": item_id - 1, \"rating\": rating}\n        return sample","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MatrixFactorizationPyTorch(nn.Module):\n    def __init__(self, n_user, n_item, k=20):\n        \"\"\"\n        n_user: user num\n        n_item: item num\n        k: embedding dim\n        \"\"\"\n        super().__init__()\n        self.user_factors = nn.Embedding(n_user, k, sparse=True)\n        self.item_factors = nn.Embedding(n_item, k, sparse=True)\n\n    def forward(self, user, item):\n        #print(user, item)\n        u_emb = self.user_factors(user)\n        i_emb = self.item_factors(item)\n        # print(u_emb.shape, i_emb.shape)\n        # print((u_emb * i_emb).shape)\n        # print((u_emb * i_emb).sum(axis=1).shape)\n        return (u_emb * i_emb).sum(axis=1)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(MovieLensDataset(train_df), batch_size=2, shuffle=True,)\nnext(iter(train_loader))","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"{'user': tensor([670, 485]),\n 'item': tensor([ 11, 251]),\n 'rating': tensor([5, 3])}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = next(iter(train_loader))\nuser, item = data['user'], data['item']\nmodel = MatrixFactorizationPyTorch(n_user, n_item, k=config.embedding_dim)\nmodel(user, item)","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"tensor([5.9666, 9.7543], grad_fn=<SumBackward1>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# train"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_one_epoch(epoch, model, loss_fn, optimizer,\n                    train_loader, device, scheduler=None):\n    model.train()\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    data_cnt = 0\n    total_loss = 0.0\n\n    # 学習データをシャッフルしてループ\n    for step, data in pbar:\n        user = data['user']\n        item = data['item']\n        rating = data['rating']\n        data_cnt += user.shape[0]\n\n        # 勾配リセット\n        optimizer.zero_grad()\n\n        #順伝搬、逆伝搬\n        outputs = model(user, item)\n        #print('outupts', outputs)\n        #print(rating)\n        loss = loss_fn(outputs,  rating.float())\n        #print('loss', loss)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        #print(total_loss)\n        if ((step + 1) % config.verbose_step == 0) or ((step + 1) == len(train_loader)):\n            description = f'train epoch {epoch} loss: {total_loss / data_cnt:.4f}'\n            pbar.set_description(description)\n\n    total_loss = total_loss / len(train_loader)\n    print('train loss = {:.4f}'.format(total_loss))\n\ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device):\n\n    model.eval()\n    total_loss = 0.0\n    data_cnt = 0\n    #preds = []\n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n\n    for step, data in pbar:\n        user = data['user']\n        item = data['item']\n        rating = data['rating']\n        data_cnt += user.shape[0]\n\n        outputs = model(user, item)\n        loss = loss_fn(outputs, rating)\n        total_loss += loss\n        \n        # preds.append(outputs.detach().cpu().numpy())\n\n        if ((step + 1) % config.verbose_step == 0) or ((step + 1) == len(val_loader)):\n            description = f'val epoch {epoch} loss: {total_loss / data_cnt:.4f}'\n            pbar.set_description(description)\n        \n\n    valid_loss = total_loss / len(val_loader)\n    print('val loss = {:.4f}'.format(valid_loss))\n    return valid_loss \n\ndef run_train(train_loader, valid_loader):\n    device = torch.device(config.device)\n    model = MatrixFactorizationPyTorch(n_user, n_item, k=config.embedding_dim)\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(model.parameters(), lr=config.lr)\n    best_loss=1e10\n    for epoch in range(config.epochs):\n        train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device)\n\n        with torch.no_grad():\n            val_loss = valid_one_epoch(epoch, model, loss_fn, valid_loader, device)\n        \n        if best_loss > val_loss:\n            best_loss = val_loss\n            best_rmse = torch.sqrt(best_loss)\n            best_epoch = epoch\n            # TODO: save model,  figure\n            best_path =  os.path.join(OUTPUT_DIR,f'best_model.bin')\n            torch.save({'model':model.state_dict(),},\n                           best_path)\n    print(f'----- result ------')\n    print(f'Best epoch: {epoch}')\n    print(f'Best loss: {best_loss}, RMSE: {best_rmse}')","execution_count":30,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(MovieLensDataset(train_df), batch_size=config.train_bs, shuffle=True,)\nvalid_loader = DataLoader(MovieLensDataset(valid_df), batch_size=config.valid_bs, shuffle=False,)\nrun_train(train_loader, valid_loader)","execution_count":31,"outputs":[{"output_type":"stream","text":"train epoch 0 loss: 3.2163: 100%|██████████| 10000/10000 [00:21<00:00, 474.10it/s]\nval epoch 0 loss: 2.5378:   2%|▏         | 59/2500 [00:00<00:04, 587.42it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 25.7305\n","name":"stdout"},{"output_type":"stream","text":"val epoch 0 loss: 2.5837: 100%|██████████| 2500/2500 [00:03<00:00, 661.52it/s]\n  1%|          | 51/10000 [00:00<00:19, 502.44it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 20.6697\n","name":"stdout"},{"output_type":"stream","text":"train epoch 1 loss: 2.0273: 100%|██████████| 10000/10000 [00:21<00:00, 471.84it/s]\nval epoch 1 loss: 1.9015:   3%|▎         | 73/2500 [00:00<00:03, 726.09it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 16.2183\n","name":"stdout"},{"output_type":"stream","text":"val epoch 1 loss: 1.9673: 100%|██████████| 2500/2500 [00:03<00:00, 719.90it/s]\n  0%|          | 49/10000 [00:00<00:20, 484.92it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 15.7385\n","name":"stdout"},{"output_type":"stream","text":"train epoch 2 loss: 1.3020: 100%|██████████| 10000/10000 [00:21<00:00, 463.96it/s]\nval epoch 2 loss: 1.2111:   2%|▏         | 62/2500 [00:00<00:03, 612.90it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 10.4161\n","name":"stdout"},{"output_type":"stream","text":"val epoch 2 loss: 1.2931: 100%|██████████| 2500/2500 [00:03<00:00, 683.04it/s]\n  0%|          | 48/10000 [00:00<00:20, 479.18it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 10.3452\n","name":"stdout"},{"output_type":"stream","text":"train epoch 3 loss: 0.7676: 100%|██████████| 10000/10000 [00:21<00:00, 466.98it/s]\nval epoch 3 loss: 0.8274:   2%|▏         | 60/2500 [00:00<00:04, 597.50it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 6.1411\n","name":"stdout"},{"output_type":"stream","text":"val epoch 3 loss: 0.8965: 100%|██████████| 2500/2500 [00:04<00:00, 606.76it/s]\n  0%|          | 36/10000 [00:00<00:27, 357.08it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 7.1724\n","name":"stdout"},{"output_type":"stream","text":"train epoch 4 loss: 0.5071: 100%|██████████| 10000/10000 [00:21<00:00, 465.36it/s]\nval epoch 4 loss: 0.6390:   3%|▎         | 77/2500 [00:00<00:03, 765.76it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 4.0565\n","name":"stdout"},{"output_type":"stream","text":"val epoch 4 loss: 0.6907: 100%|██████████| 2500/2500 [00:03<00:00, 685.03it/s]\ntrain epoch 5 loss: 0.4228:   0%|          | 50/10000 [00:00<00:20, 497.05it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 5.5255\n","name":"stdout"},{"output_type":"stream","text":"train epoch 5 loss: 0.3730: 100%|██████████| 10000/10000 [00:22<00:00, 435.72it/s]\nval epoch 5 loss: 0.5315:   3%|▎         | 76/2500 [00:00<00:03, 752.56it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 2.9843\n","name":"stdout"},{"output_type":"stream","text":"val epoch 5 loss: 0.5708: 100%|██████████| 2500/2500 [00:03<00:00, 659.58it/s]\ntrain epoch 6 loss: 0.2946:   1%|          | 52/10000 [00:00<00:19, 511.76it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 4.5661\n","name":"stdout"},{"output_type":"stream","text":"train epoch 6 loss: 0.2954: 100%|██████████| 10000/10000 [00:21<00:00, 460.42it/s]\nval epoch 6 loss: 0.4635:   3%|▎         | 68/2500 [00:00<00:03, 674.37it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 2.3636\n","name":"stdout"},{"output_type":"stream","text":"val epoch 6 loss: 0.4941: 100%|██████████| 2500/2500 [00:04<00:00, 621.75it/s]\n  0%|          | 39/10000 [00:00<00:26, 381.67it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 3.9527\n","name":"stdout"},{"output_type":"stream","text":"train epoch 7 loss: 0.2465: 100%|██████████| 10000/10000 [00:21<00:00, 474.89it/s]\nval epoch 7 loss: 0.4163:   2%|▏         | 60/2500 [00:00<00:04, 593.60it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.9720\n","name":"stdout"},{"output_type":"stream","text":"val epoch 7 loss: 0.4414: 100%|██████████| 2500/2500 [00:03<00:00, 696.42it/s]\ntrain epoch 8 loss: 0.2336:   0%|          | 50/10000 [00:00<00:19, 498.03it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 3.5313\n","name":"stdout"},{"output_type":"stream","text":"train epoch 8 loss: 0.2135: 100%|██████████| 10000/10000 [00:21<00:00, 459.62it/s]\nval epoch 8 loss: 0.3832:   2%|▏         | 59/2500 [00:00<00:04, 587.96it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.7078\n","name":"stdout"},{"output_type":"stream","text":"val epoch 8 loss: 0.4036: 100%|██████████| 2500/2500 [00:03<00:00, 653.16it/s]\ntrain epoch 9 loss: 0.1777:   0%|          | 49/10000 [00:00<00:20, 484.54it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 3.2289\n","name":"stdout"},{"output_type":"stream","text":"train epoch 9 loss: 0.1900: 100%|██████████| 10000/10000 [00:21<00:00, 474.22it/s]\nval epoch 9 loss: 0.3583:   3%|▎         | 76/2500 [00:00<00:03, 752.66it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.5203\n","name":"stdout"},{"output_type":"stream","text":"val epoch 9 loss: 0.3753: 100%|██████████| 2500/2500 [00:03<00:00, 636.14it/s]\n  0%|          | 49/10000 [00:00<00:20, 482.43it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 3.0023\n","name":"stdout"},{"output_type":"stream","text":"train epoch 10 loss: 0.1727: 100%|██████████| 10000/10000 [00:20<00:00, 480.58it/s]\nval epoch 10 loss: 0.3379:   3%|▎         | 69/2500 [00:00<00:03, 689.93it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.3815\n","name":"stdout"},{"output_type":"stream","text":"val epoch 10 loss: 0.3532: 100%|██████████| 2500/2500 [00:03<00:00, 702.50it/s]\n  0%|          | 38/10000 [00:00<00:26, 372.09it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.8260\n","name":"stdout"},{"output_type":"stream","text":"train epoch 11 loss: 0.1594: 100%|██████████| 10000/10000 [00:21<00:00, 467.20it/s]\nval epoch 11 loss: 0.3231:   3%|▎         | 77/2500 [00:00<00:03, 764.94it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.2752\n","name":"stdout"},{"output_type":"stream","text":"val epoch 11 loss: 0.3358: 100%|██████████| 2500/2500 [00:03<00:00, 718.83it/s]\n  0%|          | 48/10000 [00:00<00:20, 478.54it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.6866\n","name":"stdout"},{"output_type":"stream","text":"train epoch 12 loss: 0.1489: 100%|██████████| 10000/10000 [00:20<00:00, 478.15it/s]\nval epoch 12 loss: 0.3104:   3%|▎         | 73/2500 [00:00<00:03, 720.36it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.1914\n","name":"stdout"},{"output_type":"stream","text":"val epoch 12 loss: 0.3216: 100%|██████████| 2500/2500 [00:03<00:00, 680.09it/s]\n  1%|          | 52/10000 [00:00<00:19, 512.66it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.5732\n","name":"stdout"},{"output_type":"stream","text":"train epoch 13 loss: 0.1405: 100%|██████████| 10000/10000 [00:22<00:00, 450.72it/s]\nval epoch 13 loss: 0.3005:   3%|▎         | 70/2500 [00:00<00:03, 698.31it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.1242\n","name":"stdout"},{"output_type":"stream","text":"val epoch 13 loss: 0.3098: 100%|██████████| 2500/2500 [00:03<00:00, 690.94it/s]\n  0%|          | 47/10000 [00:00<00:21, 469.02it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.4785\n","name":"stdout"},{"output_type":"stream","text":"train epoch 14 loss: 0.1336: 100%|██████████| 10000/10000 [00:22<00:00, 452.65it/s]\nval epoch 14 loss: 0.2920:   3%|▎         | 71/2500 [00:00<00:03, 708.77it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.0690\n","name":"stdout"},{"output_type":"stream","text":"val epoch 14 loss: 0.3001: 100%|██████████| 2500/2500 [00:03<00:00, 670.47it/s]\ntrain epoch 15 loss: 0.1305:   1%|          | 51/10000 [00:00<00:19, 509.08it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.4005\n","name":"stdout"},{"output_type":"stream","text":"train epoch 15 loss: 0.1279: 100%|██████████| 10000/10000 [00:21<00:00, 462.89it/s]\nval epoch 15 loss: 0.2849:   3%|▎         | 74/2500 [00:00<00:03, 731.31it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 1.0228\n","name":"stdout"},{"output_type":"stream","text":"val epoch 15 loss: 0.2917: 100%|██████████| 2500/2500 [00:03<00:00, 655.99it/s]\ntrain epoch 16 loss: 0.1170:   1%|          | 52/10000 [00:00<00:19, 511.64it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.3338\n","name":"stdout"},{"output_type":"stream","text":"train epoch 16 loss: 0.1230: 100%|██████████| 10000/10000 [00:21<00:00, 462.58it/s]\nval epoch 16 loss: 0.2792:   3%|▎         | 70/2500 [00:00<00:03, 693.36it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.9840\n","name":"stdout"},{"output_type":"stream","text":"val epoch 16 loss: 0.2846: 100%|██████████| 2500/2500 [00:03<00:00, 702.56it/s]\ntrain epoch 17 loss: 0.1137:   1%|          | 53/10000 [00:00<00:19, 521.78it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.2766\n","name":"stdout"},{"output_type":"stream","text":"train epoch 17 loss: 0.1188: 100%|██████████| 10000/10000 [00:22<00:00, 450.49it/s]\nval epoch 17 loss: 0.2736:   2%|▏         | 58/2500 [00:00<00:04, 570.44it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.9506\n","name":"stdout"},{"output_type":"stream","text":"val epoch 17 loss: 0.2782: 100%|██████████| 2500/2500 [00:03<00:00, 680.96it/s]\n  0%|          | 47/10000 [00:00<00:21, 466.34it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.2254\n","name":"stdout"},{"output_type":"stream","text":"train epoch 18 loss: 0.1152: 100%|██████████| 10000/10000 [00:21<00:00, 465.23it/s]\nval epoch 18 loss: 0.2693:   3%|▎         | 75/2500 [00:00<00:03, 745.73it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.9218\n","name":"stdout"},{"output_type":"stream","text":"val epoch 18 loss: 0.2727: 100%|██████████| 2500/2500 [00:03<00:00, 689.29it/s]\n  0%|          | 50/10000 [00:00<00:19, 499.66it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.1817\n","name":"stdout"},{"output_type":"stream","text":"train epoch 19 loss: 0.1121: 100%|██████████| 10000/10000 [00:21<00:00, 475.70it/s]\nval epoch 19 loss: 0.2651:   3%|▎         | 74/2500 [00:00<00:03, 735.53it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.8966\n","name":"stdout"},{"output_type":"stream","text":"val epoch 19 loss: 0.2679: 100%|██████████| 2500/2500 [00:03<00:00, 643.66it/s]\ntrain epoch 20 loss: 0.1123:   0%|          | 50/10000 [00:00<00:20, 496.08it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.1433\n","name":"stdout"},{"output_type":"stream","text":"train epoch 20 loss: 0.1093: 100%|██████████| 10000/10000 [00:22<00:00, 446.85it/s]\nval epoch 20 loss: 0.2625:   3%|▎         | 69/2500 [00:00<00:03, 685.89it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.8744\n","name":"stdout"},{"output_type":"stream","text":"val epoch 20 loss: 0.2637: 100%|██████████| 2500/2500 [00:04<00:00, 600.14it/s]\n  0%|          | 49/10000 [00:00<00:20, 485.83it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.1095\n","name":"stdout"},{"output_type":"stream","text":"train epoch 21 loss: 0.1068: 100%|██████████| 10000/10000 [00:20<00:00, 478.83it/s]\nval epoch 21 loss: 0.2595:   3%|▎         | 76/2500 [00:00<00:03, 751.30it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.8546\n","name":"stdout"},{"output_type":"stream","text":"val epoch 21 loss: 0.2600: 100%|██████████| 2500/2500 [00:03<00:00, 645.51it/s]\n  0%|          | 36/10000 [00:00<00:28, 354.99it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.0798\n","name":"stdout"},{"output_type":"stream","text":"train epoch 22 loss: 0.1046: 100%|██████████| 10000/10000 [00:22<00:00, 442.95it/s]\nval epoch 22 loss: 0.2563:   3%|▎         | 71/2500 [00:00<00:03, 706.62it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.8370\n","name":"stdout"},{"output_type":"stream","text":"val epoch 22 loss: 0.2564: 100%|██████████| 2500/2500 [00:03<00:00, 711.56it/s]\n  0%|          | 49/10000 [00:00<00:20, 486.02it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.0509\n","name":"stdout"},{"output_type":"stream","text":"train epoch 23 loss: 0.1026: 100%|██████████| 10000/10000 [00:21<00:00, 457.81it/s]\nval epoch 23 loss: 0.2541:   3%|▎         | 69/2500 [00:00<00:03, 683.71it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.8210\n","name":"stdout"},{"output_type":"stream","text":"val epoch 23 loss: 0.2533: 100%|██████████| 2500/2500 [00:03<00:00, 680.13it/s]\n  0%|          | 48/10000 [00:00<00:20, 477.41it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.0264\n","name":"stdout"},{"output_type":"stream","text":"train epoch 24 loss: 0.1008: 100%|██████████| 10000/10000 [00:21<00:00, 466.62it/s]\nval epoch 24 loss: 0.2521:   3%|▎         | 77/2500 [00:00<00:03, 761.12it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.8067\n","name":"stdout"},{"output_type":"stream","text":"val epoch 24 loss: 0.2505: 100%|██████████| 2500/2500 [00:03<00:00, 711.79it/s]\ntrain epoch 25 loss: 0.0922:   0%|          | 50/10000 [00:00<00:19, 499.08it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 2.0043\n","name":"stdout"},{"output_type":"stream","text":"train epoch 25 loss: 0.0992: 100%|██████████| 10000/10000 [00:21<00:00, 476.04it/s]\nval epoch 25 loss: 0.2498:   3%|▎         | 73/2500 [00:00<00:03, 728.10it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7937\n","name":"stdout"},{"output_type":"stream","text":"val epoch 25 loss: 0.2480: 100%|██████████| 2500/2500 [00:03<00:00, 658.03it/s]\n  0%|          | 49/10000 [00:00<00:20, 489.79it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.9839\n","name":"stdout"},{"output_type":"stream","text":"train epoch 26 loss: 0.0977: 100%|██████████| 10000/10000 [00:21<00:00, 467.83it/s]\nval epoch 26 loss: 0.2474:   2%|▏         | 57/2500 [00:00<00:04, 562.31it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7817\n","name":"stdout"},{"output_type":"stream","text":"val epoch 26 loss: 0.2457: 100%|██████████| 2500/2500 [00:03<00:00, 691.58it/s]\n  0%|          | 36/10000 [00:00<00:28, 353.81it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.9657\n","name":"stdout"},{"output_type":"stream","text":"train epoch 27 loss: 0.0963: 100%|██████████| 10000/10000 [00:21<00:00, 472.23it/s]\nval epoch 27 loss: 0.2463:   2%|▏         | 59/2500 [00:00<00:04, 580.80it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7706\n","name":"stdout"},{"output_type":"stream","text":"val epoch 27 loss: 0.2436: 100%|██████████| 2500/2500 [00:03<00:00, 700.51it/s]\n  0%|          | 49/10000 [00:00<00:20, 477.87it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.9487\n","name":"stdout"},{"output_type":"stream","text":"train epoch 28 loss: 0.0950: 100%|██████████| 10000/10000 [00:22<00:00, 452.60it/s]\nval epoch 28 loss: 0.2451:   3%|▎         | 78/2500 [00:00<00:03, 772.98it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7604\n","name":"stdout"},{"output_type":"stream","text":"val epoch 28 loss: 0.2416: 100%|██████████| 2500/2500 [00:03<00:00, 637.24it/s]\n  0%|          | 39/10000 [00:00<00:26, 381.38it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.9331\n","name":"stdout"},{"output_type":"stream","text":"train epoch 29 loss: 0.0939: 100%|██████████| 10000/10000 [00:21<00:00, 458.03it/s]\nval epoch 29 loss: 0.2439:   3%|▎         | 73/2500 [00:00<00:03, 720.13it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7511\n","name":"stdout"},{"output_type":"stream","text":"val epoch 29 loss: 0.2398: 100%|██████████| 2500/2500 [00:03<00:00, 665.72it/s]\n  0%|          | 49/10000 [00:00<00:20, 488.36it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.9184\n","name":"stdout"},{"output_type":"stream","text":"train epoch 30 loss: 0.0928: 100%|██████████| 10000/10000 [00:21<00:00, 460.03it/s]\nval epoch 30 loss: 0.2424:   2%|▏         | 59/2500 [00:00<00:04, 588.66it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7423\n","name":"stdout"},{"output_type":"stream","text":"val epoch 30 loss: 0.2383: 100%|██████████| 2500/2500 [00:03<00:00, 628.25it/s]\n  0%|          | 38/10000 [00:00<00:26, 378.26it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.9063\n","name":"stdout"},{"output_type":"stream","text":"train epoch 31 loss: 0.0917: 100%|██████████| 10000/10000 [00:20<00:00, 492.78it/s]\nval epoch 31 loss: 0.2415:   3%|▎         | 75/2500 [00:00<00:03, 740.46it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7340\n","name":"stdout"},{"output_type":"stream","text":"val epoch 31 loss: 0.2368: 100%|██████████| 2500/2500 [00:03<00:00, 695.22it/s]\n  0%|          | 39/10000 [00:00<00:25, 384.36it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8942\n","name":"stdout"},{"output_type":"stream","text":"train epoch 32 loss: 0.0908: 100%|██████████| 10000/10000 [00:23<00:00, 429.64it/s]\nval epoch 32 loss: 0.2407:   2%|▏         | 59/2500 [00:00<00:04, 580.29it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7264\n","name":"stdout"},{"output_type":"stream","text":"val epoch 32 loss: 0.2354: 100%|██████████| 2500/2500 [00:04<00:00, 604.90it/s]\n  1%|          | 51/10000 [00:00<00:19, 508.65it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8829\n","name":"stdout"},{"output_type":"stream","text":"train epoch 33 loss: 0.0899: 100%|██████████| 10000/10000 [00:21<00:00, 460.77it/s]\nval epoch 33 loss: 0.2396:   3%|▎         | 76/2500 [00:00<00:03, 757.93it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7189\n","name":"stdout"},{"output_type":"stream","text":"val epoch 33 loss: 0.2341: 100%|██████████| 2500/2500 [00:03<00:00, 698.29it/s]\n  0%|          | 50/10000 [00:00<00:20, 496.12it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8726\n","name":"stdout"},{"output_type":"stream","text":"train epoch 34 loss: 0.0890: 100%|██████████| 10000/10000 [00:22<00:00, 437.19it/s]\nval epoch 34 loss: 0.2386:   3%|▎         | 75/2500 [00:00<00:03, 749.18it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7124\n","name":"stdout"},{"output_type":"stream","text":"val epoch 34 loss: 0.2329: 100%|██████████| 2500/2500 [00:04<00:00, 566.58it/s]\ntrain epoch 35 loss: 0.0906:   0%|          | 50/10000 [00:00<00:19, 499.62it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8631\n","name":"stdout"},{"output_type":"stream","text":"train epoch 35 loss: 0.0883: 100%|██████████| 10000/10000 [00:21<00:00, 458.42it/s]\nval epoch 35 loss: 0.2378:   2%|▏         | 58/2500 [00:00<00:04, 579.08it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7061\n","name":"stdout"},{"output_type":"stream","text":"val epoch 35 loss: 0.2317: 100%|██████████| 2500/2500 [00:03<00:00, 670.68it/s]\n  0%|          | 48/10000 [00:00<00:21, 473.71it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8535\n","name":"stdout"},{"output_type":"stream","text":"train epoch 36 loss: 0.0875: 100%|██████████| 10000/10000 [00:22<00:00, 446.95it/s]\nval epoch 36 loss: 0.2372:   3%|▎         | 77/2500 [00:00<00:03, 766.91it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.7000\n","name":"stdout"},{"output_type":"stream","text":"val epoch 36 loss: 0.2306: 100%|██████████| 2500/2500 [00:03<00:00, 695.97it/s]\n  0%|          | 50/10000 [00:00<00:20, 494.06it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8450\n","name":"stdout"},{"output_type":"stream","text":"train epoch 37 loss: 0.0868: 100%|██████████| 10000/10000 [00:21<00:00, 458.93it/s]\nval epoch 37 loss: 0.2367:   3%|▎         | 74/2500 [00:00<00:03, 732.57it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.6942\n","name":"stdout"},{"output_type":"stream","text":"val epoch 37 loss: 0.2297: 100%|██████████| 2500/2500 [00:03<00:00, 670.85it/s]\n  0%|          | 48/10000 [00:00<00:20, 476.33it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8376\n","name":"stdout"},{"output_type":"stream","text":"train epoch 38 loss: 0.0861: 100%|██████████| 10000/10000 [00:21<00:00, 469.04it/s]\nval epoch 38 loss: 0.2360:   3%|▎         | 74/2500 [00:00<00:03, 737.95it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.6887\n","name":"stdout"},{"output_type":"stream","text":"val epoch 38 loss: 0.2288: 100%|██████████| 2500/2500 [00:03<00:00, 638.92it/s]\n  1%|          | 51/10000 [00:00<00:19, 507.40it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8307\n","name":"stdout"},{"output_type":"stream","text":"train epoch 39 loss: 0.0854: 100%|██████████| 10000/10000 [00:21<00:00, 459.99it/s]\nval epoch 39 loss: 0.2354:   3%|▎         | 74/2500 [00:00<00:03, 731.80it/s]","name":"stderr"},{"output_type":"stream","text":"train loss = 0.6835\n","name":"stdout"},{"output_type":"stream","text":"val epoch 39 loss: 0.2280: 100%|██████████| 2500/2500 [00:03<00:00, 684.40it/s]","name":"stderr"},{"output_type":"stream","text":"val loss = 1.8237\n----- result ------\nBest epoch: 39\nBest loss: 1.8237441778182983, RMSE: 1.3504607677459717\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# get recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\nitem_df = pd.read_csv(os.path.join(DATA_DIR, 'u.item'), sep='|', encoding=\"iso-8859-1\", usecols=range(5), names=m_cols)\nitem_df.head()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"   movie_id              title release_date  video_release_date  \\\n0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n4         5     Copycat (1995)  01-Jan-1995                 NaN   \n\n                                            imdb_url  \n0  http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n1  http://us.imdb.com/M/title-exact?GoldenEye%20(...  \n2  http://us.imdb.com/M/title-exact?Four%20Rooms%...  \n3  http://us.imdb.com/M/title-exact?Get%20Shorty%...  \n4  http://us.imdb.com/M/title-exact?Copycat%20(1995)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>video_release_date</th>\n      <th>imdb_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model():\n    best_path = os.path.join(OUTPUT_DIR, 'best_model.bin')\n    model = MatrixFactorizationPyTorch(n_user, n_item, k=20)\n    model.load_state_dict(torch.load(best_path)['model'])\n    return model\n\ndef predict_rating(rec_df):\n    \"\"\"\n    predict unwatched item ratings\n    \"\"\"\n    model = load_model()\n    model.eval()\n    dataloader = DataLoader(MovieLensDataset(rec_df), batch_size=10, shuffle=False,)\n    pbar = tqdm(dataloader, total=len(dataloader))\n    preds = []\n    for data in pbar:\n        user_id = data['user']\n        item_id = data['item']\n        rating = data['rating']\n\n        preds += model(user_id, item_id)\n\n    return torch.stack(preds).detach().numpy()\n\ndef recommend_for_user(user_id, rating_df, item_df, top_n=10):\n    \"\"\"\n    \"\"\"\n    rec_df = rating_df.query(\"user_id != @user_id\")\n    rec_df['user_id'] = user_id\n    rec_df = rec_df.drop_duplicates(subset=['user_id','item_id'])\n    rec_df['rating'] = predict_rating(rec_df)\n    \n    # clip rating\n    rec_df = rec_df.query('0.5 <= rating <= 5.5 ')\n\n    # add title column \n    d = dict(zip(item_df.movie_id, item_df.title))\n    rec_df['title'] = rec_df['item_id'].map(d)\n    rec_df = rec_df.sort_values('rating', ascending=False)\n\n    # show recommend movies\n    print('-'*30 + 'recommendations' + '-'*30)\n    print(rec_df[['title','rating']].head(top_n))\n#     for i, row in rec_df.head(top_n).iterrows():\n#         title, rating = row['title'],row['rating']\n#         print(f'{i:}: title:{title}  score:{rating}')\n\n    # show movies which user have watched before\n    user_df = rating_df.query(\"user_id == @user_id\")\n    user_df['title'] = user_df['item_id'].map(d)\n    user_df = user_df.sort_values('rating', ascending=False)\n\n    print('-'*30 + 'watched_movies' + '-'*30)\n    print(user_df[['title','rating']].head(top_n))\n#     for i, row in user_df.head(top_n).iterrows():\n#         title, rating = row['title'], row['rating']\n#         print(f'{i}: title:{title}  score:{rating}')\n\n","execution_count":109,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_id = random.choice(df.user_id.values)\nprint(user_id)\nrecommend_for_user(user_id, df, item_df)","execution_count":112,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n 33%|███▎      | 56/169 [00:00<00:00, 558.64it/s]","name":"stderr"},{"output_type":"stream","text":"495\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 169/169 [00:00<00:00, 563.28it/s]","name":"stderr"},{"output_type":"stream","text":"------------------------------recommendations------------------------------\n                                    title    rating\n4682                My Man Godfrey (1936)  5.490833\n746   Fast, Cheap & Out of Control (1997)  5.426092\n671        American President, The (1995)  5.407290\n7288                 Nobody's Fool (1994)  5.400203\n6519        Great Day in Harlem, A (1994)  5.365497\n1270                   Sling Blade (1996)  5.325870\n1676        In the Bleak Midwinter (1995)  5.307295\n243               Schindler's List (1993)  5.293337\n313      Shawshank Redemption, The (1994)  5.292449\n383             Dazed and Confused (1993)  5.281991\n------------------------------watched_movies------------------------------\n                                title  rating\n23410  Raiders of the Lost Ark (1981)       5\n33036    Pink Floyd - The Wall (1982)       5\n60868   Independence Day (ID4) (1996)       5\n39673              Up in Smoke (1978)       5\n60993  Remains of the Day, The (1993)       5\n39509          Terminator, The (1984)       5\n39164         Army of Darkness (1993)       5\n61585               Young Guns (1988)       5\n61800               Striptease (1996)       5\n63597               Gridlock'd (1997)       5\n","name":"stdout"},{"output_type":"stream","text":"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}